{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing keras\n",
    "# from keras.utils import layer_utils\n",
    "# from keras.utils.data_utils import get_file\n",
    "# from keras.applications.imagenet_utils import decode_predictions\n",
    "# from keras.applications.imagenet_utils import preprocess_input\n",
    "# from keras.applications.imagenet_utils import _obtain_input_shape \n",
    "# from keras.engine.topology import get_source_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagong', 'gareng', 'petruk', 'semar']\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"images\"\n",
    "\n",
    "# List all files in the dataset folder\n",
    "files_in_dataset = os.listdir(dataset_folder)\n",
    "print(files_in_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spllit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"images\", output=\"output\",\n",
    "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2248 images belonging to 4 classes.\n",
      "Found 281 images belonging to 4 classes.\n",
      "Found 281 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'output/train',\n",
    "    target_size=(225, 175),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    'output/val',\n",
    "    target_size=(225, 175),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'output/test',\n",
    "    target_size=(225, 175),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give label to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'bagong', 1: 'gareng', 2: 'petruk', 3: 'semar'}\n"
     ]
    }
   ],
   "source": [
    "labels_dict = train_generator.class_indices\n",
    "wayang_labels = dict((v, k) for k, v in labels_dict.items())\n",
    "print(wayang_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset:  2810\n"
     ]
    }
   ],
   "source": [
    "dataset_counts = []\n",
    "total_dataset_count = 0\n",
    "\n",
    "for root, _, fileList in os.walk('output'):\n",
    "    for _, label in wayang_labels.items():\n",
    "        if label in root:\n",
    "            dataset_counts.append(len(fileList))\n",
    "            total_dataset_count += len(fileList)\n",
    "\n",
    "print (\"Total dataset: \", total_dataset_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Class Weighting -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classes = train_generator.num_classes\n",
    "# class_labels = np.unique(train_classes)\n",
    "# class_weights = sklearn.utils.class_weight.compute_class_weight('balanced', class_labels, train_classes)\n",
    "\n",
    "# class_weights_dict = dict(zip(class_labels, class_weights))\n",
    "# print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 2479s 35s/step - loss: 4.2357 - accuracy: 0.2923 - val_loss: 1.4088 - val_accuracy: 0.3167\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 2512s 35s/step - loss: 1.3723 - accuracy: 0.3141 - val_loss: 1.3955 - val_accuracy: 0.3167\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 2507s 35s/step - loss: 1.3721 - accuracy: 0.3123 - val_loss: 1.3685 - val_accuracy: 0.3167\n",
      "Epoch 4/10\n",
      "35/71 [=============>................] - ETA: 27:14 - loss: 1.3601 - accuracy: 0.3268"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(175, 225, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)  # Replace num_classes with the number of classes in your dataset\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
